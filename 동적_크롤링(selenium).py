# -*- coding: utf-8 -*-
"""동적 크롤링(selenium).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XZ7Ctvpf6g8yCyzZ_DxiGbJIJnF6dl_V
"""

pip install selenium

pip install webdriver-manager

!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver '/content/drive/MyDrive/Colab Notebooks' #
!pip install chromedriver-autoinstaller

import requests
import bs4
import selenium
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from webdriver_manager.chrome import ChromeDriverManager
import time

#chrome driver를 구글 드라이브에 저장하는 코드
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
import sys
from selenium.webdriver.common.keys import Keys
import urllib.request
import os
from urllib.request import urlretrieve

import time
import pandas as pd
import chromedriver_autoinstaller  # setup chrome options

chrome_path = "/content/drive/MyDrive/Colab Notebooks/chromedriver"
sys.path.insert(0,chrome_path)

#셀레니움 버전문제 해결 코드
options = webdriver.ChromeOptions()
options.add_argument('--headless')        # Head-less 설정
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome( options=options)

"""스타트업 얼라이언스 웹스크래핑

내가 긁어오고 싶어하는 부분은 동적 웹스크래핑을 해야한다...

참고 사이트 :
1. https://hi-guten-tag.tistory.com/?page=47
2.https://imdona.tistory.com/39 (예시 참고하기)
3.https://m.blog.naver.com/mdown/222102495356 (동적 웹스크래핑이 필요한지 판단하는 법)
4.https://velog.io/@ssongji/%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81-3.-selenium%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EB%8F%99%EC%A0%81%EC%9D%B8-%ED%8E%98%EC%9D%B4%EC%A7%80%EC%9D%98-XPath%EB%A1%9C-%EC%9B%90%ED%95%98%EB%8A%94-%EC%9A%94%EC%86%8C-%EC%8A%A4%ED%81%AC%EB%9E%98%ED%95%91 (동적 웹스크래핑 하는 법)
5.https://nicedeveloper.tistory.com/entry/%ED%81%AC%EB%A1%AC%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B2%84-%EC%97%90%EB%9F%AC-service-option-browser-driver (셀레니움 버전 문제 해결)
6.https://velog.io/@kite_day/colab-%EC%97%90%EC%84%9C-%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0-selenium (코랩에서 웹스크래핑하기)
7.https://dejavuqa.tistory.com/109 (selenium.by 명령어)
8.https://splayer.tistory.com/16 (문자열에서 숫자만 추출)
"""

url = "https://startupspace.kr/"
requests.get(url)
res = requests.get(url)
print('실제 웹페이지: %s' %url)
res.content # 수집된 HTML cnffur

"""Beautifulsoup를 이용한 startup alliance 정적 크롤링"""

soup = bs4.BeautifulSoup(res.content, 'html.parser')
soup.prettify()

soup.find('div').get_text()

soup.find('body').find('div')

print(soup.find('div',{'class':'css-kcl69l'}))

"""Beautifulsoup를 이용한 혁신의 숲 정적 크롤링"""

url2 = "https://www.innoforest.co.kr/"
requests.get(url2)
res2 = requests.get(url2)
res2.raise_for_status()
soup2 = bs4.BeautifulSoup(res2.content, 'html.parser')
#결과값 출력
soup2.find('div').get_text()
print(soup2.find('div',{'class':'corp css-h6bbsr'}))
print(soup2.select('body id._next'))

"""동적 웹스크래핑"""

driver.get("https://startupspace.kr/")
#driver.page_source   #사이트에 HTML 코드를 가져옴
driver.find_element(By.XPATH ,value='//*[@id="__next"]/div/div[4]/div/div[4]/div[1]/div/div/div[1]/div/button[2]').click()
#사이트 카드 버튼을 눌러주는 코드

items = driver.find_elements(By.CSS_SELECTOR, '#__next > div > div:nth-child(5) > div > div.css-grw20s > div:nth-child(2) > div > div > div > div > div > div:nth-child(1) > div > div > div:nth-child(5) > a > div.css-kcl69l')
items.text   #CSS로 파싱

#사이트에서 스타트업회사 파싱 XML로 파싱
ad=driver.find_element(By.XPATH, '//*[@id="__next"]/div/div[4]/div/div[4]/div[2]/div/div/div/div/div/div[1]/div/div/div[1]/a/div[2]').text #XML로 파싱
ad